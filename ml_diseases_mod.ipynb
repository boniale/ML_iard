{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Age-Related Conditions Using Machine Learning Models\n",
    "## Author: Boni M. Ale, MD, MSc, MPH\n",
    "### Date: 08 June 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine if someone has these medical conditions requires a long and intrusive process to collect information from patients. With predictive models, we can shorten this process and keep patient details private by collecting key characteristics relative to the conditions, then encoding these characteristics.\n",
    "\n",
    "In this project, I will use Machine Learning to detect conditions with measurements of anonymous characteristics. Therefore the general objective of this analysis is to predict if a person has any of three medical conditions. In order to predict if the person has one or more of any of the three medical conditions (Class 1), or none of the three medical conditions (Class 0), I will create a model trained on anonymous measurements of health characteristics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv('/Users/boniale/Desktop/Data_Science/ML_iard/data/train.csv')\n",
    "test = pd.read_csv('/Users/boniale/Desktop/Data_Science/ML_iard/data/test.csv')\n",
    "greeks_raw = pd.read_csv('/Users/boniale/Desktop/Data_Science/ML_iard/data/greeks.csv')\n",
    "sample_submission = pd.read_csv('/Users/boniale/Desktop/Data_Science/ML_iard/data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Raw Train Data Set's size: \", train_raw.shape)\n",
    "\n",
    "print(\"Raw Greeks Data Set's size: \", greeks_raw.shape)\n",
    "\n",
    "#separate variables into new data frames\n",
    "numeric_data = train_raw.select_dtypes(include=[np.number])\n",
    "cat_data = train_raw.select_dtypes(exclude=[np.number])\n",
    "cat_data = cat_data.drop(['Id'], axis=1)\n",
    "print (\"There are {} numeric and {} categorical columns in train raw data\".format(numeric_data.shape[1],cat_data.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like there is 56 numeric variables which include our target (\"if the person has one or more of any of the three medical conditions (Class 1)\" or \"none of the three medical conditions (Class 0)\"). This means that Class is actually a categorical variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Numerical Variables Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's work on numeriacal features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target = ['Class']\n",
    "allFeature = train_raw.columns.tolist()\n",
    "included_features = [feature for feature in allFeature if feature not in Target]\n",
    "\n",
    "numericalFeatures = train_raw[included_features].select_dtypes(include=['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericalFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is actually 55 numeric variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the overall distribution of these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = [f for f in train_raw.columns if train_raw.dtypes[f] != 'object']\n",
    "num.remove(\"Class\")\n",
    "nd = pd.melt(train_raw, value_vars = num)\n",
    "barplot_train = sns.FacetGrid (nd, col='variable',\n",
    "                    col_wrap=5, \n",
    "                    sharex=False, \n",
    "                              sharey = False\n",
    "                   )\n",
    "barplot_train = barplot_train.map(sns.histplot, 'value')\n",
    "plt.show(\"barplot_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that several variables are not normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the data confirmed the imbalance distribution of features among those who have the diseases and those who doesn't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are these variables highly correlated among each other ? Let's explore this visually with a heatmap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Display a correlation heatmap Function\n",
    "def display_correlation_heatmap(df, title):\n",
    "    corr_mat = np.round(df.corr(), 3)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    sns.heatmap(corr_mat, annot=True, fmt=\".3f\", cmap='coolwarm', cbar=False, square=True, linewidths=.5, annot_kws={\"size\": 12}, ax=ax)\n",
    "\n",
    "    ax.set_title(title, fontsize=16, pad=20, y=1.05)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=12)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "       \n",
    "def plot_correlation_heatmap(df, column_name):\n",
    "    correlation_matrix = df.corr()\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "    plt.title(f'Correlation heatmap for {column_name}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a correlation heatmap\n",
    "def plot_top_correlations(df: pd.core.frame.DataFrame, n: int, title_name: str='Top Correlations') -> None:\n",
    "    # Calculate correlation between all variables\n",
    "    corr = df.corr()\n",
    "\n",
    "    # Select variables having highest absolute correlation\n",
    "    top_corr_cols = corr.abs().nlargest(n, columns=corr.columns).index\n",
    "    top_corr = corr.loc[top_corr_cols, top_corr_cols]\n",
    "\n",
    "    fig, axes = plt.subplots(figsize=(10, 5))\n",
    "    mask = np.zeros_like(top_corr)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    sns.heatmap(top_corr, mask=mask, linewidths=.5, cmap='YlOrRd', annot=True)\n",
    "    plt.title(title_name)\n",
    "    plt.show()\n",
    "\n",
    "# Plot heatmap of top 12 correlations in training data\n",
    "plot_top_correlations(num_data, 10, 'Top 10 Correlations in Train Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some variables are correlate but not highly correlated in general apart from variable BZ and BC which are highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Target Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's first calculate the frequence table for those have one or more of any of the three medical conditions (Class 1), or none of the three medical conditions (Class 0). Secondly, we will generate the percentages in each group. Finaly, I will do a visualisation to show the distribution of our target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Frequency Table of Class*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_tab = pd.crosstab(index = train_raw[\"Class\"],  # Make a crosstab\n",
    "                     columns=\"Total\")                  # Name the count column\n",
    "freq_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Percentage Table of Class*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_tab = pd.crosstab(index = train_raw[\"Class\"],  # Make a crosstab\n",
    "                     columns=\"Percentage\")                  # Name the count column\n",
    "\n",
    "my_tab/my_tab.sum()*100 # Calculate the percentages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Visualisation of Class*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define data\n",
    "data_targ = [17.5 , 82.5]\n",
    "labels = ['Has medical condition', 'No medical condition']\n",
    "\n",
    "#define Seaborn color palette to use\n",
    "colors = sns.color_palette('pastel')[0:50]\n",
    "\n",
    "#create pie chart\n",
    "plt.pie(data_targ, labels = labels, colors = colors, autopct='%.0f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This look like an imbalance data as the number of people who has one or more of any of the three medical conditions is quite smaller than people with none of the three medical conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Relationship between Target and Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the distribution of our features among people who has one or more of any of the three medical conditions and  those with none of the three medical conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (4*4, 20)\n",
    "fig = plt.figure(figsize=figsize)\n",
    "for idx, col in enumerate(numericalFeatures):\n",
    "    ax = plt.subplot(14,4, idx + 1)\n",
    "    sns.kdeplot(\n",
    "        hue='Class',\n",
    "        data=train_raw, fill=True,\n",
    "        x=col, palette=[\"Gray\", \"Red\"], legend=False\n",
    "    )\n",
    "            \n",
    "    ax.set_ylabel(''); ax.spines['top'].set_visible(False), \n",
    "    ax.set_xlabel(''); ax.spines['right'].set_visible(False)\n",
    "    ax.set_title(f'{col}', loc='center', \n",
    "                 weight='bold', fontsize=20)\n",
    "\n",
    "fig.suptitle(f'Features distribution among people with one or more of any of the three medical conditions and those with none\\n\\n\\n', ha='center',  fontweight='bold', fontsize=21)\n",
    "fig.legend([1, 0], loc='upper center', bbox_to_anchor=(0.5, 0.96), fontsize=21, ncol=3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the data confirmed the imbalance distribution of our features and target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2.5.1. Data Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "oversample = RandomOverSampler(random_state=0)\n",
    "X, y = oversample.fit_resample(x_scaled, y)\n",
    "# summarize distribution\n",
    "counter = Counter(y)\n",
    "for k,v in counter.items():\n",
    "\tper = v / len(y) * 100\n",
    "\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2.5.2. Data Scalling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sc=StandardScaler()\n",
    "x_scaled = sc.fit_transform(numericalFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#conver categorical daata in numerical for categorical column [eg]\n",
    "train_raw['EJ'] = train_raw['EJ'].replace({'A': 0, 'B': 1})\n",
    "test['EJ'] = test['EJ'].replace({'A': 0, 'B': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
